{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection as sk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as kb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "%matplotlib widget\n",
    "# Check if GPU is available\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate input and output signals\n",
    "Generates the dataset used for training the network\n",
    "The last bit will split it in training and test blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate very simple dataset\n",
    "curIt = 21;\n",
    "# Trial temporal profile\n",
    "frameRate = 10\n",
    "prestimulusTime = 1\n",
    "stimulusDuration = 1.5\n",
    "\n",
    "Ntrials = 64*500 # Per difficulty\n",
    "\n",
    "# Psychometric parameters\n",
    "lapseRate = 0.1\n",
    "alpha = (3/90, 10/90) # For the (low, high) attention states\n",
    "\n",
    "# Difficulties\n",
    "angleList = np.linspace(-90, 90, 13)\n",
    "angleValue = np.linspace(-1, 1, len(angleList)) # 1-1 mapping with angleList\n",
    "angleDifficulty = np.unique(abs(angleList)) # 0 to 90\n",
    "\n",
    "totalFrames = int((prestimulusTime+stimulusDuration)*frameRate)\n",
    "timeVec = np.arange(totalFrames)/frameRate\n",
    "stimulusFrame = np.argmin(abs(timeVec-prestimulusTime))\n",
    "\n",
    "# Generate the psychometric curves (prob choosing left) angle variable is |thetaR|-|thetaL|\n",
    "ScurveLeftLow = 1/(1+np.exp(-alpha[0]*angleList))*(1-lapseRate)+lapseRate/2\n",
    "ScurveLeftHigh = 1/(1+np.exp(-alpha[1]*angleList))*(1-lapseRate)+lapseRate/2\n",
    "def Scurve(angleDiff, alpha, lapse): \n",
    "    p = 1/(1+np.exp(-alpha*angleDiff))*(1-lapse)+lapse/2\n",
    "    return p\n",
    "\n",
    "# Balanced dataset for each difficulty and attention level\n",
    "\n",
    "# Let's generate the angle list for the dataset\n",
    "NtrialsFull = Ntrials*len(angleDifficulty) # Ntrials per difficulty\n",
    "\n",
    "angleData = np.zeros((NtrialsFull, 2)) # Stores the 2 stimuli angles of each trial\n",
    "angleDataIdx = np.zeros((NtrialsFull, 2)) # The idx in the angle vector of the 2 angles\n",
    "angleDataDifficulty = np.zeros(NtrialsFull) # The trial difficulty (angle difference) ||theta_R|-|theta_L||\n",
    "idealChoice = np.zeros(NtrialsFull) # The correct choice for that trial |theta_R|>|theta_L| ?\n",
    "trainedChoice = np.zeros(NtrialsFull) # The choice used to train (from the psych curve)\n",
    "attentionLevel = np.zeros(NtrialsFull, dtype=int) # Attention level of that trial\n",
    "\n",
    "for it in range(angleData.shape[0]):\n",
    "    curDifficulty = angleDifficulty[it // Ntrials]\n",
    "    # Allowed angles for each difficulty - we start with positive angles for simplicity\n",
    "    validAngles = angleDifficulty[np.argwhere(angleDifficulty >= curDifficulty)]\n",
    "    firstAngle = validAngles[np.random.choice(len(validAngles))]\n",
    "    secondAngle = firstAngle - curDifficulty\n",
    "    # Now randomize sign (180 deg rotation)\n",
    "    anglePair = (int(np.random.choice((-1,1))*firstAngle), int(np.random.choice((-1,1))*secondAngle))\n",
    "    # Now randomize order (left vs right)\n",
    "    anglePair = np.random.permutation(anglePair)\n",
    "    angleData[it, :] = anglePair\n",
    "    angleDataIdx[it, :] = [np.argwhere(anglePair[0] == angleList), np.argwhere(anglePair[1] == angleList)]\n",
    "    angleDataDifficulty[it] = (np.diff(abs(anglePair)))\n",
    "    # Choose attention level (at random)\n",
    "    attentionLevel[it] = np.random.choice((0, 1))\n",
    "    # Find the correct choice |theta_R|>|theta_L| ? - if equal, choose at random\n",
    "    if(np.diff(abs(anglePair)) > 0):\n",
    "        idealChoice[it] = 0\n",
    "    elif(np.diff(abs(anglePair)) < 0):\n",
    "        idealChoice[it] = 1\n",
    "    else:\n",
    "        idealChoice[it] = np.random.choice((0, 1))\n",
    "    # Compute the psych probability\n",
    "    probLeft = Scurve(angleDataDifficulty[it], alpha[attentionLevel[it]], lapseRate)\n",
    "    \n",
    "    # Choose the outcome of the trial\n",
    "    if(np.random.random(1) < probLeft):\n",
    "        trainedChoice[it] = 0\n",
    "    else:\n",
    "        trainedChoice[it] = 1    \n",
    "\n",
    "# Now that we have defined each trial create the time series\n",
    "trialsData = np.zeros((NtrialsFull, totalFrames, 3)).astype(np.float32)\n",
    "responseData  = np.full((NtrialsFull, totalFrames), np.nan)\n",
    "\n",
    "\n",
    "for it in range(NtrialsFull):\n",
    "    #if trainedChoice[it] == 0:\n",
    "    trialsData[it, stimulusFrame:, 0] = angleValue[int(angleDataIdx[it, 0])]\n",
    "    #else:\n",
    "    trialsData[it, stimulusFrame:, 1] = angleValue[int(angleDataIdx[it, 1])]\n",
    "    trialsData[it, 1:, 2] = attentionLevel[it]\n",
    "    responseData[it, stimulusFrame-1] = 0 # Frame before the stimulus - stay QUIET!\n",
    "    responseData[it, -1] = trainedChoice[it]+1 # 1/2 left right\n",
    "\n",
    "trialsData += np.random.randn(*trialsData.shape)/10\n",
    "\n",
    "xTrain, xTest, yTrain, yTest, angleDataDifficultyTrain , angleDataDifficultyTest, trainedChoiceTrain, trainedChoiceTest, angleDataTrain, angleDataTest, idealChoiceTrain, idealChoiceTest, attentionLevelTrain, attentionLevelTest, = sk.train_test_split(trialsData,\n",
    "                          responseData,\n",
    "                          angleDataDifficulty,\n",
    "                          trainedChoice,\n",
    "                          angleData,\n",
    "                          idealChoice,\n",
    "                          attentionLevel,\n",
    "                          test_size=0.25,\n",
    "                          random_state=12)\n",
    "\n",
    "\n",
    "units = 256 # Number of neurons in the dense layer\n",
    "output_size = 3 # Number of output states\n",
    "\n",
    "# Only use 2 frames: 1. Before the stimulus (so both left and right prob are 0). 2. The last frame\n",
    "\n",
    "def custom_loss(y_actual,y_pred): \n",
    "    l1 = kb.sparse_categorical_crossentropy(y_actual[:, stimulusFrame-1], y_pred[:, stimulusFrame-1])\n",
    "    l2 = kb.sparse_categorical_crossentropy(y_actual[:, -1], y_pred[:, -1])\n",
    "    custom_loss = l1 + l2\n",
    "    return custom_loss\n",
    "\n",
    "# Only use the last frame\n",
    "def custom_cat(y_actual,y_pred): \n",
    "    l2 = tf.keras.metrics.sparse_categorical_accuracy(y_actual[:, -1], y_pred[:, -1])\n",
    "    custom_cat = l2\n",
    "\n",
    "    return custom_cat\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.SimpleRNN(units, activation = 'relu', input_shape = (xTrain.shape[1], xTrain.shape[2]),\n",
    "    return_sequences = True, name = 'rnn'))\n",
    "model.add(layers.BatchNormalization(name = 'batch_norm'))\n",
    "model.add(layers.Dense(output_size, activation = 'softmax', name = 'outputprobs'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 640 # Trials per batch\n",
    "MAX_EPOCHS = 250 # Total epochs\n",
    "\n",
    "model.compile(\n",
    "    loss=custom_loss,\n",
    "    optimizer=\"adam\",\n",
    "    metrics=custom_cat,\n",
    ")\n",
    "history = model.fit(xTrain, yTrain, epochs = MAX_EPOCHS, batch_size = batch_size, verbose = True,\n",
    "   validation_data = (xTest, yTest))\n",
    "yTestPredict = model.predict(xTest)\n",
    "\n",
    "# Save everything to MATLAB\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=(model.get_layer(name=\"rnn\").output, model.get_layer(name=\"outputprobs\").output, model.outputs),\n",
    ")\n",
    "yTestPredict = model.predict(xTest)\n",
    "# Call feature extractor on test input.\n",
    "y = tf.convert_to_tensor(xTest,  dtype='float32')\n",
    "fet = feature_extractor(y)\n",
    "tracesN = fet[0].numpy()\n",
    "tracesP = fet[1].numpy()\n",
    "sio.savemat('trainedModel' + str(curIt) + '.mat', {'trialsData':xTest, 'responseData': yTest, \n",
    "                                 'responseDataPrediction': yTestPredict, 'angleDataDifficulty': angleDataDifficultyTest, \n",
    "                                  'trainedChoice': trainedChoiceTest, 'idealChoice': idealChoiceTest, 'attentionLevel': attentionLevelTest, \n",
    "                                  'alpha': alpha, 'lapseRate': lapseRate, 'Ntrials': Ntrials, 'frameRate': frameRate, \n",
    "                                  'prestimulusTime': prestimulusTime, 'stimulusDuration': stimulusDuration, 'angleList': angleList,\n",
    "                                  'angleDifficulty': angleDifficulty, 'angleValue': angleValue, 'tracesN': tracesN, 'tracesP': tracesP})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
